displayed_sidebar: docs
import QSOverview from '../_assets/commonMarkdown/quickstart-overview-tip.mdx'

# 架构

好的


StarRocks 具有出色的架构。整个系统只包含两种类型的组件：“前端节点”和“后端节点”。前端节点称为 **FE**。后端节点分为两种类型：**BE** 和 **CN**（计算节点）。当数据使用本地存储时，部署 BE；当数据存储在对象存储或 HDFS 上时，部署 CN。StarRocks 不依赖任何外部组件，这简化了部署和维护。节点可以水平扩展而无需停机。此外，StarRocks 对元数据和服务数据采用副本机制，提高了数据可靠性，有效防止了单点故障 (SPOF)。

StarRocks 兼容 MySQL 通信协议并支持标准 SQL。用户可以通过 MySQL 客户端连接到 StarRocks，即时获取有价值的洞察。

## 架构选择

StarRocks 支持存算一体模式（每个 BE 在其本地存储上拥有一部分数据）和存算分离模式（所有数据都存储在对象存储或 HDFS 上，每个 CN 只在其本地存储上有一个缓存）。您可以根据需要决定数据存储位置。

![架构选择](../_assets/architecture_choices.png)

### 存算一体模式
本地存储为实时查询提供了更好的查询延迟。

作为典型的海量并行处理 (MPP) 数据库，StarRocks 支持存算一体架构。在此架构中，BE 负责数据存储和计算。直接访问 BE 节点上的本地数据可以实现本地计算，避免数据传输和数据复制，提供超快的查询和数据分析性能。该架构支持多副本数据存储，增强了集群处理高并发查询的能力，并确保了数据可靠性。它非常适合需要最佳查询性能的场景。

![存算一体架构](../_assets/shared-nothing.png)

#### 节点

在存算一体架构中，StarRocks 由两种类型的节点组成：FE 和 BE。

- FE 负责元数据管理和构建执行计划。
- BE 执行查询计划和存储数据。BE 利用本地存储加速查询，并使用多副本机制确保数据高可用性。

##### FE

FE 负责元数据管理、客户端连接管理、查询规划和查询调度。每个 FE 都使用 BDB JE (Berkeley DB Java Edition) 在其内存中存储和维护完整的元数据副本，确保所有 FE 之间的服务一致性。FE 可以作为 Leader、Follower 和 Observer 运行。如果 Leader 节点崩溃，Follower 将根据 Raft 协议选举出 Leader。

| **FE 角色** | **元数据管理**                                                                                                                                                                                                                                                                                                                                                                                                | **Leader 选举**                    |
| ----------- |--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| ---------------------------------- |
| Leader      | Leader FE 读取和写入元数据。Follower 和 Observer FE 只能读取元数据。它们将元数据写入请求路由到 Leader FE。Leader FE 更新元数据，然后使用 Raft 协议将元数据更改同步到 Follower 和 Observer FE。只有当元数据更改同步到半数以上的 Follower FE 后，数据写入才被认为是成功的。 | Leader FE 从技术上讲也是一个 Follower 节点，由 Follower FE 选举产生。要执行 Leader 选举，集群中必须有半数以上的 Follower FE 处于活跃状态。当 Leader FE 故障时，Follower FE 将发起新一轮 Leader 选举。 |
| Follower    | Follower 只能读取元数据。它们同步并重放来自 Leader FE 的日志以更新元数据。                                                                                                                                                                                                                                                                                                                                             | Follower 参与 Leader 选举，这要求集群中半数以上的 Follower 处于活跃状态。 |
| Observer   | 同步并重放来自 Leader FE 的日志以更新元数据。                                                                                                                                                                                                                                                                                                                                                                          | Observer 主要用于提高集群的查询并发性。Observer 不参与 Leader 选举，因此不会增加集群的 Leader 选举压力。 |

##### BE

BE 负责数据存储和 SQL 执行。

- 数据存储：BE 具有等效的数据存储能力。FE 根据预定义规则将数据分发给 BE。BE 转换摄入的数据，以所需格式写入数据，并为数据生成索引。

- SQL 执行：FE 根据查询的语义将每个 SQL 查询解析为逻辑执行计划，然后将逻辑计划转换为可在 BE 上执行的物理执行计划。存储目标数据的 BE 执行查询。这消除了数据传输和复制的需要，从而实现高查询性能。

### 存算分离模式

对象存储和 HDFS 在成本、可靠性和可扩展性方面具有优势。除了存储的可扩展性之外，由于存储与计算分离，CN 节点可以按需添加和删除，无需重新平衡数据。

在存算分离架构中，BE 被“计算节点（CN）”取代，CN 仅负责数据计算任务和缓存热数据。数据存储在低成本、可靠的远程存储系统（如 Amazon S3、Google Cloud Storage、Azure Blob Storage、MinIO 等）中。当缓存命中时，查询性能与存算一体架构相当。CN 节点可以在几秒钟内按需添加或删除。这种架构降低了存储成本，确保了更好的资源隔离，并提供了高弹性和可扩展性。

存算分离架构与存算一体架构一样，保持了简单的设计。它只包含两种类型的节点：FE 和 CN。唯一的区别是用户需要提供一个后端对象存储。

![存算分离架构](../_assets/shared-data.png)

#### 节点

存算分离架构中的协调节点提供与存算一体架构中 FE 相同的功能。

BE 被 CN（计算节点）取代，存储功能被卸载到对象存储或 HDFS。CN 是无状态的计算节点，执行除数据存储之外的所有 BE 功能。

#### 存储

StarRocks 存算分离集群支持两种存储解决方案：对象存储（如 AWS S3、Google GCS、Azure Blob Storage 或 MinIO）和 HDFS。

在存算分离集群中，数据文件格式与存算一体集群（具有紧密耦合的存储和计算）保持一致。数据被组织成段文件，各种索引技术在 Cloud-native tables 中得到重用，Cloud-native tables 是专门用于存算分离集群的表。

#### 缓存

StarRocks 存算分离集群将数据存储与计算解耦，允许它们独立扩展，从而降低成本并增强弹性。然而，这种架构可能会影响查询性能。

为了缓解这种影响，StarRocks 建立了一个涵盖内存、本地磁盘和远程存储的多层数据访问系统，以更好地满足各种业务需求。

热数据查询直接扫描缓存，然后扫描本地磁盘；而冷数据需要从对象存储加载到本地缓存以加速后续查询。通过将热数据保持在靠近计算单元的位置，StarRocks 实现了真正的高性能计算和经济高效的存储。此外，通过数据预取策略优化了冷数据访问，有效消除了查询性能限制。

在创建表时可以启用缓存。如果启用缓存，数据将同时写入本地磁盘和后端对象存储。在查询期间，CN 节点首先从本地磁盘读取数据。如果未找到数据，则将从后端对象存储中检索数据并同时缓存到本地磁盘。

<QSOverview />
